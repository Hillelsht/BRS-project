output_dir: data/

apis: [YahooBursaFetcher]
instruments: # instrument: market
  SPY: NYSE Arca 
  AAPL: NASDAQ
  GLD: NYSE Arca
  EURUSD=X: FX
  EEM: NYSE Arca
  NVDA: NASDAQ
  MSFT: NASDAQ
  ^GSPC: S&P 500

features_list: ['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Capital Gains', 'Instrument', 'Market', 'day_of_week', 'month', 'hour', 'MA_5', 'MA_10', 'Close_pct_change', 'Volume_pct_change']


# fetching parameters
to_fetch: True # False - load previously saved data
fetch_date: '2024-05-19'

historical_params:
  period: "730d" # "1y" "60d"
  interval: "1h" # 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo

# preprocessing parameters
preprocessing:
  to_preprocess: True # False - load previously saved data
  preprocess_date: '2024-05-19'

labeling:
  to_label: True
  label_date: '2024-05-19'


learning: # learning Label_Price_Direction - Classification Problem
  time_seperator: ['2023-05-01', '2023-11-01', '2024-05-01'] #time separation between the datasets
  to_learn: True
  learning_date: '2024-02-08' # the date of running learning. Used to load data preprocessed within learning
  
  # the best performance.
  model_params:
    xgboost:
      module_path: xgboost
      model_type: XGBClassifier
      train_params:
        booster: gbtree
        learning_rate: 0.01
        n_estimators: 1500
        max_depth: 8
        min_child_weight: 1
        gamma: 0
        subsample: 0.8
        colsample_bytree: 0.6
        objective: binary:logistic
        random_state: 42
        eval_metric: aucpr
        reg_alpha: 0.01
        reg_lambda: 10
      fit_params:
        verbose: False
    lightgbm:
      module_path: lightgbm
      model_type: LGBMClassifier
      train_params:
        boosting_type: gbdt
        learning_rate: 0.1
        n_estimators: 50
        max_depth: 4
        num_leaves: 100
        min_child_samples: 3
        subsample: 0.9
        colsample_bytree: 0.8
        objective: binary
        random_state: 42
        reg_alpha: 1
        reg_lambda: 10
      fit_params: {}



learning_future_close:
  to_learn: True # if false - load previously cost predicted data
  learning_date: '2024-01-16' # the date of running learning. Used to load data preprocessed within learning
  price_master: cost/price_master.xlsx
  learner: CostLearner
  model_params:
    xgboost:
      module_path: xgboost
      model_type: XGBRegressor
      train_params:
        booster: gbtree
        learning_rate: 0.01
        n_estimators: 1000 # 1500 - overfitting, 100 - regular fit 
        max_depth: 10 # 15 - overfitting, 5 - regular fit 
        min_child_weight: 10
        gamma: 0
        subsample: 0.8
        colsample_bytree: 0.5
        objective: reg:squarederror
        random_state: 42
        eval_metric: rmse
        reg_alpha: 0
        reg_lambda: 1
      fit_params:
        verbose: False

    lightgbm:
      module_path: lightgbm
      model_type: LGBMRegressor
      train_params:
        boosting_type: gbdt          
        learning_rate: 0.01          
        n_estimators: 1500 # 1500 - overfitting, 100 - regular fit 
        max_depth: 30 # 15 - overfitting, 5 - regular fit 
        num_leaves: 255               
        min_child_samples: 10        
        min_child_weight: 0.00001      
        subsample: 1.0               
        colsample_bytree: 0.9       
        objective: regression        
        random_state: 42             
        metric: rmse                 
        reg_alpha: 1              
        reg_lambda: 1               
        silent: False                
      fit_params: {}